services:
  app:
    container_name: consultancy_pricing_app_prod
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      - PYTHONUNBUFFERED=1
      - ENVIRONMENT=production
      # CORS: specify allowed origins (comma-separated)
      - CORS_ORIGINS=${CORS_ORIGINS}
      # External PostgreSQL connection (Cloud SQL, RDS, Azure Database, etc.)
      # Format examples:
      #   Cloud SQL (private IP): INSTANCE_CONNECTION_NAME=10.x.x.x:5432
      #   Cloud SQL (Cloud SQL Proxy): INSTANCE_CONNECTION_NAME=/cloudsql/project:region:instance
      #   AWS RDS: INSTANCE_CONNECTION_NAME=mydb.xyz.region.rds.amazonaws.com:5432
      #   Azure Database: INSTANCE_CONNECTION_NAME=myserver.postgres.database.azure.com:5432
      - INSTANCE_CONNECTION_NAME=${INSTANCE_CONNECTION_NAME}
      - DB_USER=${DB_USER}
      - DB_PASS=${DB_PASS}
      - DB_NAME=${DB_NAME:-consultancy_pricing}
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

# Production uses external managed database service (Cloud SQL, RDS, etc.)
# No PostgreSQL container needed
#
# Database setup checklist:
# 1. Create managed PostgreSQL instance in your cloud provider
# 2. Configure firewall/VPC to allow container access
# 3. Create database and user
# 4. Set connection details in .env file:
#    - INSTANCE_CONNECTION_NAME (host:port or connection string)
#    - DB_USER
#    - DB_PASS
#    - DB_NAME
# 5. For Cloud SQL, consider using Cloud SQL Proxy for secure connections
